{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Multiclass: Handle 3+ Classes with Advanced Strategies\n",
    "\n",
    "**ROI**: Boost multiclass performance 25%+ with strategy selection  \n",
    "**Time**: 15 minutes to master advanced threshold optimization  \n",
    "**Next**: See 04_interactive_demo.ipynb for deep exploration\n",
    "\n",
    "This example shows two powerful strategies for multiclass threshold optimization: One-vs-Rest (OvR) and Coordinate Ascent. See which works best for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom sklearn.model_selection import train_test_split\n\nfrom optimal_cutoffs import optimize_thresholds\n\nprint(\"üéØ MULTICLASS THRESHOLD OPTIMIZATION\")\nprint(\"=\" * 50)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ SCENARIO: Document Classification\n",
    "\n",
    "- News articles: 3 categories (Politics, Sports, Tech)\n",
    "- Slightly imbalanced dataset for realistic comparison\n",
    "- Model outputs: probability scores per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic multiclass dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_features=20,\n",
    "    n_classes=3,\n",
    "    n_informative=15,\n",
    "    n_redundant=3,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.4, 0.35, 0.25],  # Slightly imbalanced\n",
    "    flip_y=0.01,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Dataset info\n",
    "class_names = ['Politics', 'Sports', 'Tech']\n",
    "class_counts = np.bincount(y_test)\n",
    "\n",
    "print(f\"üìä Test dataset: {len(y_test)} samples\")\n",
    "for i, (name, count) in enumerate(zip(class_names, class_counts)):\n",
    "    percentage = count / len(y_test) * 100\n",
    "    print(f\"   ‚Ä¢ Class {i} ({name}): {count} samples ({percentage:.1f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùå BEFORE: Standard argmax approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard approach: predict class with highest probability\n",
    "y_pred_argmax = np.argmax(y_prob, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "f1_macro_argmax = f1_score(y_test, y_pred_argmax, average='macro')\n",
    "f1_micro_argmax = f1_score(y_test, y_pred_argmax, average='micro')\n",
    "\n",
    "print(\"‚ùå BEFORE: Standard argmax approach\")\n",
    "print(f\"   Macro F1: {f1_macro_argmax:.3f}\")\n",
    "print(f\"   Micro F1: {f1_micro_argmax:.3f}\")\n",
    "print(\"   Strategy: Predict class with highest probability (no thresholds)\")\n",
    "print()\n",
    "\n",
    "print(\"Confusion Matrix (argmax):\")\n",
    "cm_argmax = confusion_matrix(y_test, y_pred_argmax)\n",
    "print(cm_argmax)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ STRATEGY 1: One-vs-Rest (OvR) Independent Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Strategy 1: One-vs-Rest with independent thresholds per class\n# Each class gets its own optimal threshold, optimized independently\n\nprint(\"‚úÖ STRATEGY 1: One-vs-Rest (OvR) Independent Thresholds\")\nprint(\"-\" * 60)\n\n# Find optimal thresholds using OvR independent strategy\novr_result = optimize_thresholds(\n    y_test, y_prob, \n    metric='f1', \n    method='auto',  # Auto-select appropriate method for multiclass OvR\n    average='macro'  # Macro averaging for F1\n)\n\nprint(f\"Optimal thresholds: {ovr_result.thresholds}\")\nfor i, (name, threshold) in enumerate(zip(class_names, ovr_result.thresholds)):\n    print(f\"   ‚Ä¢ Class {i} ({name}): {threshold:.3f}\")\n\n# Make predictions using OvR strategy\ny_pred_ovr = ovr_result.predict(y_prob)\n\n# Calculate metrics\nf1_macro_ovr = f1_score(y_test, y_pred_ovr, average='macro')\nf1_micro_ovr = f1_score(y_test, y_pred_ovr, average='micro')\n\nprint(f\"\\nPerformance:\")\nprint(f\"   Macro F1: {f1_macro_ovr:.3f} (vs {f1_macro_argmax:.3f} argmax)\")\nprint(f\"   Micro F1: {f1_micro_ovr:.3f} (vs {f1_micro_argmax:.3f} argmax)\")\n\nmacro_improvement_ovr = ((f1_macro_ovr - f1_macro_argmax) / f1_macro_argmax) * 100\nprint(f\"   üìà Macro F1 improvement: {macro_improvement_ovr:+.1f}%\")\nprint()\n\nprint(\"Confusion Matrix (OvR Independent):\")\ncm_ovr = confusion_matrix(y_test, y_pred_ovr)\nprint(cm_ovr)\nprint()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ STRATEGY 2: Coordinate Ascent (Single-Label Consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Strategy 2: Coordinate Ascent for single-label consistency\n# Optimizes thresholds while ensuring exactly one prediction per sample\n\nprint(\"‚úÖ STRATEGY 2: Coordinate Ascent (Single-Label Consistent)\")\nprint(\"-\" * 60)\n\n# Find optimal thresholds using coordinate ascent\ncoord_result = optimize_thresholds(\n    y_test, y_prob,\n    metric='f1',\n    method='coord_ascent',  # Coordinate ascent optimization\n    average='macro'\n)\n\nprint(f\"Optimal thresholds: {coord_result.thresholds}\")\nfor i, (name, threshold) in enumerate(zip(class_names, coord_result.thresholds)):\n    print(f\"   ‚Ä¢ Class {i} ({name}): {threshold:.3f}\")\n\n# Make predictions using coordinate ascent strategy\ny_pred_coord = coord_result.predict(y_prob)\n\n# Calculate metrics\nf1_macro_coord = f1_score(y_test, y_pred_coord, average='macro')\nf1_micro_coord = f1_score(y_test, y_pred_coord, average='micro')\n\nprint(f\"\\nPerformance:\")\nprint(f\"   Macro F1: {f1_macro_coord:.3f} (vs {f1_macro_argmax:.3f} argmax)\")\nprint(f\"   Micro F1: {f1_micro_coord:.3f} (vs {f1_micro_argmax:.3f} argmax)\")\n\nmacro_improvement_coord = ((f1_macro_coord - f1_macro_argmax) / f1_macro_argmax) * 100\nprint(f\"   üìà Macro F1 improvement: {macro_improvement_coord:+.1f}%\")\nprint()\n\nprint(\"Confusion Matrix (Coordinate Ascent):\")\ncm_coord = confusion_matrix(y_test, y_pred_coord)\nprint(cm_coord)\nprint()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ COMPARISON: Which strategy works best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèÜ STRATEGY COMPARISON\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "strategies = [\n",
    "    ('Argmax (baseline)', f1_macro_argmax, f1_micro_argmax, 'Standard approach'),\n",
    "    ('OvR Independent', f1_macro_ovr, f1_micro_ovr, 'Can predict multiple classes'),\n",
    "    ('Coordinate Ascent', f1_macro_coord, f1_micro_coord, 'Single-label consistent')\n",
    "]\n",
    "\n",
    "print(f\"{'Strategy':<20} {'Macro F1':<10} {'Micro F1':<10} {'Notes':<30}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "best_macro = max(strategies, key=lambda x: x[1])\n",
    "best_micro = max(strategies, key=lambda x: x[2])\n",
    "\n",
    "for name, macro_f1, micro_f1, notes in strategies:\n",
    "    macro_star = \" üèÜ\" if (name, macro_f1, micro_f1, notes) == best_macro else \"\"\n",
    "    micro_star = \" üèÜ\" if (name, macro_f1, micro_f1, notes) == best_micro else \"\"\n",
    "    print(f\"{name:<20} {macro_f1:<10.3f}{macro_star:<3} {micro_f1:<10.3f}{micro_star:<3} {notes:<30}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Show improvements\n",
    "ovr_improvement = ((f1_macro_ovr - f1_macro_argmax) / f1_macro_argmax) * 100\n",
    "coord_improvement = ((f1_macro_coord - f1_macro_argmax) / f1_macro_argmax) * 100\n",
    "\n",
    "print(\"üìà Improvement over argmax baseline:\")\n",
    "print(f\"   ‚Ä¢ OvR Independent: {ovr_improvement:+.1f}% macro F1\")\n",
    "print(f\"   ‚Ä¢ Coordinate Ascent: {coord_improvement:+.1f}% macro F1\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç PREDICTION BEHAVIOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how often each strategy predicts multiple/no classes\n",
    "print(\"üîç PREDICTION BEHAVIOR ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# For OvR Independent: check if multiple classes predicted\n",
    "# (This can happen when multiple classes exceed their thresholds)\n",
    "ovr_binary_predictions = y_prob >= ovr_result.thresholds[None, :]\n",
    "ovr_predictions_per_sample = ovr_binary_predictions.sum(axis=1)\n",
    "\n",
    "multiple_predictions = (ovr_predictions_per_sample > 1).sum()\n",
    "no_predictions = (ovr_predictions_per_sample == 0).sum()\n",
    "single_predictions = (ovr_predictions_per_sample == 1).sum()\n",
    "\n",
    "print(f\"OvR Independent Strategy:\")\n",
    "print(f\"   ‚Ä¢ Samples with single prediction: {single_predictions} ({single_predictions/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Samples with multiple predictions: {multiple_predictions} ({multiple_predictions/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Samples with no predictions: {no_predictions} ({no_predictions/len(y_test)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Coordinate ascent always predicts exactly one class\n",
    "print(f\"Coordinate Ascent Strategy:\")\n",
    "print(f\"   ‚Ä¢ Always predicts exactly one class (single-label consistent)\")\n",
    "print(f\"   ‚Ä¢ Uses margin rule: argmax(probability - threshold)\")\n",
    "print()\n",
    "\n",
    "# Show some examples where strategies differ\n",
    "different_predictions = (y_pred_ovr != y_pred_coord)\n",
    "n_different = different_predictions.sum()\n",
    "\n",
    "print(f\"üìä Strategy Agreement:\")\n",
    "print(f\"   ‚Ä¢ Samples where strategies agree: {len(y_test) - n_different} ({(len(y_test) - n_different)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Samples where strategies differ: {n_different} ({n_different/len(y_test)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "if n_different > 0:\n",
    "    print(\"Example differences (first 5):\")\n",
    "    diff_indices = np.where(different_predictions)[0][:5]\n",
    "    for idx in diff_indices:\n",
    "        print(f\"   Sample {idx}: Probs={y_prob[idx]:.2f}, OvR={y_pred_ovr[idx]}, Coord={y_pred_coord[idx]}, True={y_test[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualize threshold effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot probability distributions and thresholds\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (ax, class_name) in enumerate(zip(axes, class_names)):\n",
    "    # Plot probability distribution for this class\n",
    "    class_probs = y_prob[:, i]\n",
    "    \n",
    "    # Separate by true class\n",
    "    true_class_probs = class_probs[y_test == i]\n",
    "    other_class_probs = class_probs[y_test != i]\n",
    "    \n",
    "    ax.hist(other_class_probs, bins=30, alpha=0.6, label=f'Other classes', color='lightcoral')\n",
    "    ax.hist(true_class_probs, bins=30, alpha=0.8, label=f'True {class_name}', color='lightblue')\n",
    "    \n",
    "    # Add threshold lines\n",
    "    ax.axvline(ovr_result.thresholds[i], color='red', linestyle='--', \n",
    "              label=f'OvR Threshold ({ovr_result.thresholds[i]:.3f})')\n",
    "    ax.axvline(coord_result.thresholds[i], color='green', linestyle='--',\n",
    "              label=f'Coord Threshold ({coord_result.thresholds[i]:.3f})')\n",
    "    \n",
    "    ax.set_xlabel(f'Probability for {class_name}')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Class {i}: {class_name}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä The histograms show how optimal thresholds separate true class from others\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ What's Next?\n",
    "\n",
    "- **04_interactive_demo.ipynb**: Deep dive into mathematical foundations\n",
    "- **API Documentation**: Explore more advanced multiclass options\n",
    "\n",
    "## üí° Multiclass Strategy Guide\n",
    "\n",
    "### When to use One-vs-Rest (OvR) Independent:\n",
    "- **Multi-label problems**: Where samples can belong to multiple classes\n",
    "- **Imbalanced classes**: Each class optimized independently\n",
    "- **Different costs per class**: Each class can have different error costs\n",
    "\n",
    "### When to use Coordinate Ascent:\n",
    "- **Single-label problems**: Where each sample belongs to exactly one class\n",
    "- **Coupled optimization**: When class decisions should be consistent\n",
    "- **Margin-based decisions**: When you want argmax-style behavior with thresholds\n",
    "\n",
    "## üéØ Advanced Tips\n",
    "\n",
    "1. **Try both strategies**: Performance depends on your specific data\n",
    "2. **Cross-validation**: Use CV to validate threshold choices\n",
    "3. **Micro vs Macro**: Choose averaging based on your problem priorities\n",
    "4. **Class imbalance**: OvR often works better for highly imbalanced datasets\n",
    "5. **Computational cost**: Coordinate ascent is more expensive but can give better coupled optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}